Now I have a comprehensive understanding of the codebase and the QA results. Let me analyze the evidence and produce the advisory JSON.

Based on my analysis of the QA results, the codebase, and the failure patterns, here are the concrete engineering recommendations:

```json
{
  "advisor": "kimi",
  "executiveSummary": "Biznesinfo AI assistant shows critical failures in 3 core areas: (1) Continuity breakdown - assistant loses company context between turns (UV012, UV019-022); (2) Wrong intent detection - analytics/tagging requests trigger sourcing fallbacks (UV018); (3) Template degradation - RFQ/checklist templates fill with placeholders instead of context. 10/22 scenarios fail strict checks. Pass rate 54.5% vs target 80%. Average usefulness 1.43/4. Root cause: context persistence gaps in multi-turn flow, insufficient intent classification guards, and missing template hydration from conversation history.",
  "priorityPlan": [
    {
      "priority": "P0",
      "title": "Fix context carryover for company identification across turns",
      "why": "UV012, UV019-022 all fail because assistant cannot maintain company context. When user says 'Ирис Интер групп' in Turn 1, Turn 2 requests for 'their website' or 'check on card' fail with 'link gate' or random companies. This is the highest-impact fix.",
      "expectedImpact": "Resolves 5 failed scenarios (UV012, UV019-022), reduces hallucination of wrong companies by ~80%",
      "validationScenarios": ["UV012", "UV019", "UV020", "UV021", "UV022"]
    },
    {
      "priority": "P0",
      "title": "Add strict intent guards to prevent sourcing fallback on analytics requests",
      "why": "UV018 fails because tagging/analytics requests trigger supplier-search fallback. The looksLikeAnalyticsTaggingRequest() detection exists but doesn't block the fallback path. Assistant returns rubric categories instead of 20 GA/Metrika tags.",
      "expectedImpact": "Resolves UV018, prevents category contamination in non-sourcing contexts",
      "validationScenarios": ["UV018"]
    },
    {
      "priority": "P1",
      "title": "Implement template hydration from conversation context",
      "why": "UV001, UV003, UV006, UV007, UV016 all show templates with 'уточняется' placeholders instead of extracted values (product, qty, city, deadline). The extractTemplateFillHints() function exists but values aren't being applied.",
      "expectedImpact": "Improves usefulness score by ~1.5 points on template scenarios, makes RFQ/checklist outputs actionable",
      "validationScenarios": ["UV001", "UV003", "UV006", "UV007", "UV016"]
    },
    {
      "priority": "P1",
      "title": "Fix ranking fallback to respect multi-turn constraints",
      "why": "UV002, UV004, UV015 fail because ranking fallback ignores quality criteria (whiteness/gluten for flour, OEM/ODM for juicers, 4 criteria for tractors). Assistant returns generic 'check data' instead of structured comparison.",
      "expectedImpact": "Resolves 3 scenarios, improves comparison quality across all multi-turn sourcing flows",
      "validationScenarios": ["UV002", "UV004", "UV015"]
    },
    {
      "priority": "P2",
      "title": "Add anti-hallucination guard for company type verification",
      "why": "UV012 shows critical hallucination: polyclinics and hospitals returned as shoe manufacturers. Need stronger guardrails when search results don't match requested rubric.",
      "expectedImpact": "Prevents dangerous misclassification, improves trust in shortlist outputs",
      "validationScenarios": ["UV012", "UV009", "UV011"]
    }
  ],
  "recommendations": [
    {
      "id": "R1",
      "area": "prompt",
      "title": "Inject company context into system prompt for website scan turns",
      "action": "When looksLikeWebsiteResearchIntent() returns true AND history contains company name mentions (extractCompanyNameHintsFromText), prepend to system prompt: 'User previously mentioned company: {name}. Use this company for website checks unless user explicitly requests a different one.'",
      "implementationHint": "app/src/app/api/ai/request/route.ts: collectWebsiteResearchCompanyNameHints() exists but results aren't injected into prompt. Modify buildSystemPrompt() to accept companyHints and include them.",
      "expectedImpact": "Fixes UV019-022 context loss, enables proper 'check their website' flow",
      "risk": "Low - additive context, no breaking changes",
      "effort": "S",
      "validationScenarios": ["UV019", "UV020", "UV021", "UV022"]
    },
    {
      "id": "R2",
      "area": "guardrails",
      "title": "Block sourcing actions when analytics/tagging intent detected",
      "action": "In the main request handler, if looksLikeAnalyticsTaggingRequest() returns true, skip vendor search entirely and return a dedicated tagging response. Never execute biznesinfoSearch() or return rubric hints for tagging requests.",
      "implementationHint": "app/src/app/api/ai/request/route.ts: Add early return guard after intent detection (~line 280). Create buildAnalyticsTagsReply() function that returns structured tags without catalog fallback.",
      "expectedImpact": "Fixes UV018, prevents category contamination",
      "risk": "Low - isolated path for specific intent",
      "effort": "S",
      "validationScenarios": ["UV018"]
    },
    {
      "id": "R3",
      "area": "template",
      "title": "Force template hydration before response finalization",
      "action": "After LLM response received, if templateRequested mode detected, run applyTemplateFillHints() unconditionally and verify no placeholder patterns remain. If placeholders persist, re-prompt LLM with explicit fill instructions.",
      "implementationHint": "app/src/app/api/ai/request/route.ts: In finalize path (~line 2100+), add post-processing step: if mode.templateRequested, text = applyTemplateFillHints(text, hints); if still has {placeholder}, trigger one-shot correction.",
      "expectedImpact": "Eliminates 'уточняется' placeholders in UV001, UV003, UV006, UV007, UV016",
      "risk": "Low - post-processing only",
      "effort": "M",
      "validationScenarios": ["UV001", "UV003", "UV006", "UV007", "UV016"]
    },
    {
      "id": "R4",
      "area": "retrieval",
      "title": "Persist vendor candidates in conversation context for ranking turns",
      "action": "When Turn 1 finds companies, store vendorCandidateIds in ai_assistant_turns table. On Turn 2+ ranking requests, retrieve these candidates instead of re-searching. Use existing vendor_candidate_ids column that's already defined but underutilized.",
      "implementationHint": "app/src/lib/ai/conversations.ts: appendAssistantSessionTurn() already accepts vendorCandidateIds. Ensure route.ts passes them. In ranking turn, query previous turn's candidates via getAssistantSessionHistory() or add getLastTurnCandidates().",
      "expectedImpact": "Fixes UV002, UV004, UV015 ranking failures due to context loss",
      "risk": "Medium - requires DB query pattern",
      "effort": "M",
      "validationScenarios": ["UV002", "UV004", "UV015"]
    },
    {
      "id": "R5",
      "area": "ranking",
      "title": "Extract and apply quality criteria from user constraints",
      "action": "When user specifies criteria (e.g., 'белизна, клейковина, стабильность' for flour), extract these via pattern matching and include in ranking appendix. Modify buildRankingFallbackAppendix() to accept criteria list and format as comparison matrix.",
      "implementationHint": "app/src/app/api/ai/request/route.ts: Add extractQualityCriteria() function that parses comma-separated criteria from message. Pass to buildRankingFallbackAppendix() and render as 'Сравнение по критериям: 1. {criteria1}...'",
      "expectedImpact": "UV002, UV004 pass strict checks for criteria inclusion",
      "risk": "Low - additive to ranking output",
      "effort": "S",
      "validationScenarios": ["UV002", "UV004"]
    },
    {
      "id": "R6",
      "area": "guardrails",
      "title": "Add rubric mismatch detection for search results",
      "action": "After biznesinfoSearch(), verify returned companies match requested rubric. If primary_rubric_name contains 'медицин' but query was for 'обувь', trigger honest fallback instead of returning mismatched results.",
      "implementationHint": "app/src/app/api/ai/request/route.ts: Post-search validation function. Check if candidate.primary_rubric_name contains anti-indicators (медицин, поликлиник, больниц) when query contains target indicators (обувь, производитель).",
      "expectedImpact": "Prevents UV012 critical hallucination (polyclinics as shoe manufacturers)",
      "risk": "Low - validation layer only",
      "effort": "S",
      "validationScenarios": ["UV012", "UV009", "UV011"]
    },
    {
      "id": "R7",
      "area": "prompt",
      "title": "Strengthen anti-link-gate system prompt instruction",
      "action": "Add explicit system prompt rule: 'NEVER ask user to send links or company cards. If company mentioned in conversation history, assume that company for all subsequent requests. If unsure which company, ask clarifying question about company name, not about links.'",
      "implementationHint": "app/src/app/api/ai/request/route.ts: Add to buildSystemPrompt() guardrails section. Current anti-link-gate exists in checks but not in generation guidance.",
      "expectedImpact": "Reduces UV019-022 'пришлите ссылку' responses",
      "risk": "Low - prompt text only",
      "effort": "S",
      "validationScenarios": ["UV019", "UV020", "UV021", "UV022"]
    },
    {
      "id": "R8",
      "area": "ui",
      "title": "Add scenario tag to response metadata for debugging",
      "action": "Include detected intent tags (analytics, sourcing, ranking, template) in responseMeta for each turn. This enables faster regression identification in QA reports.",
      "implementationHint": "app/src/app/api/ai/request/route.ts: In responseMeta construction, add detectedIntents: { analytics: bool, sourcing: bool, ranking: bool, template: bool }.",
      "expectedImpact": "Improves observability, faster debug of misclassified scenarios",
      "risk": "None - metadata only",
      "effort": "S",
      "validationScenarios": ["UV018", "UV001-022"]
    }
  ],
  "testPlan": {
    "mustPassScenarios": [
      "UV012",
      "UV018",
      "UV019",
      "UV020",
      "UV021",
      "UV022"
    ],
    "regressionSuites": [
      "scenarios.regressions.user-ideas-multistep-variants.json",
      "scenarios.regressions.template-announcement.json"
    ],
    "successMetrics": [
      "strictPassRate >= 0.80 (target: 18/22 scenarios)",
      "avgUsefulness >= 2.5 (current: 1.43)",
      "usefulRate >= 0.50 (current: 0.136)",
      "zero hallucination of wrong company types (UV012 class errors)",
      "zero link-gate responses when company in context (UV019-022 class errors)",
      "zero sourcing fallback on analytics requests (UV018 class errors)"
    ]
  }
}
```
