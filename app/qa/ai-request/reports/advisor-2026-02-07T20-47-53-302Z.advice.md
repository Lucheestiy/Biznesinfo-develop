# Advisor Report — advisor-2026-02-07T20-47-53-302Z

- Generated: 2026-02-07T20:50:01.362Z
- QA report: /home/mlweb/biznesinfo-develop.lucheestiy.com/app/qa/ai-request/reports/latest.json
- Judge report: /home/mlweb/biznesinfo-develop.lucheestiy.com/app/qa/ai-request/reports/latest.usefulness.json
- Focus scenarios: 11
- Advisors: gemini, kimi

## Focus Scenarios

- D005 (fail, usefulness 2/5): Dirty query: бухучет аутсорс ООО Минск
- D001 (fail, usefulness 3.5/5): Dirty query: типография визитки срочно
- D008 (pass, usefulness 1.5/5): Dirty query: уборка после ремонта
- D011 (pass, usefulness 1.5/5): Regression: молоко Брест -> сырье 1.5% -> вывоз в Витебск
- D006 (pass, usefulness 2/5): Dirty query: вентиляция склад проект+монтаж
- D003 (pass, usefulness 3.5/5): Dirty query: реф-перевозки маршрут и цена
- D007 (pass, usefulness 4/5): Dirty query: сертификат соответствия
- D010 (pass, usefulness 4/5): Dirty query: как добавить компанию
- D002 (pass, usefulness 4.5/5): Dirty query: проверка УНП
- D004 (pass, usefulness 4.5/5): Dirty query: металлопрокат опт
- D009 (pass, usefulness 4.5/5): Dirty query: коробки с логотипом

## Consensus

- Top areas:
  - qa: 5
  - prompt: 2
  - retrieval: 1
  - geo: 1
  - guardrails: 1
  - template: 1
  - ranking: 1
- Recurring recommendations:
  - dynamic re-query with accumulated constraints (1)
  - enforce specific company presentation over general rubrics (1)
  - transparent handling of 'no results' and data limitations (1)
  - contextualize general advice for identified companies (1)
  - inject candidate memory into turn 3+ ranking prompts (1)
  - add explicit company path requirement to structured output schema (1)
  - enable partial unp search for verification queries (1)
  - add micro-district location filtering in responses (1)
  - remove over-aggressive 'avoid hallucination' fallback triggers (1)
  - add contract clause templates for service queries (1)
  - implement explicit candidate tracking across turns (1)
  - add automated continuity check to qa suite (1)

## gemini

- Summary: The Biznesinfo AI assistant currently achieves its target pass rate for strict checks, indicating functional correctness in basic responses. However, judge evaluations reveal significantly lower usefulness scores (Gemini: 3.7/5, Kimi: 2.7/5), primarily due to: 1) Context Loss: Frequent inability to retain and apply user-provided constraints across turns, leading to generic fallbacks. 2) Lack of Specificity: Tendency to provide abstract rubrics or search instructions instead of concrete company names, rankings, or tailored advice derived from the Biznesinfo catalog, even when such data should be available. 3) Inadequate Filtering: Struggles to incorporate detailed user-specified filters (e.g., location, product attributes, time-sensitive terms) into search results. Addressing these core issues will significantly improve user satisfaction and the assistant's perceived utility.

### Priority Plan

- P0 — Enhance Multi-Turn Context Retention and Application
  why: This directly addresses the primary cause of low usefulness and context loss, which undermines the assistant's intelligence. Generic fallbacks erode user trust and efficiency.
  impact: Significant reduction in generic responses, higher relevance of results, improved user satisfaction and task completion rates.
  validate: D001, D005, D006, D008, D011, D003
- P0 — Prioritize Concrete Shortlists and Specific Actionable Advice
  why: Directly addresses the 'lack of specificity' issue, making the assistant's output immediately actionable for the user. Users expect direct answers, especially in a 'rushed buyer' context.
  impact: Increased utility of responses, better alignment with the 'rushed buyer' persona, leading to quicker decision-making for users.
  validate: D001, D005, D006, D008, D011, D003
- P1 — Refine Retrieval and Filtering Mechanisms
  why: Enables the assistant to deliver more precise and relevant results based on detailed user requirements, reducing instances where specific constraints are ignored or mishandled.
  impact: Fewer instances of missed constraints, more accurate company suggestions, and higher precision in filtered results.
  validate: D001, D011

### Recommendations

- [R1] (qa, effort M) Dynamic Re-query with Accumulated Constraints
  action: Modify the prompt engineering and/or retrieval logic to explicitly construct or refine search queries by combining the initial user intent with *all subsequent, explicit constraints* (e.g., location, product specifications, delivery terms) from previous turns. When a new constraint is introduced, the system should re-execute or refine the search against the Biznesinfo catalog with the *cumulative* parameters. If no…
  hint: Within the agent's logic, maintain a state object for active search parameters. On each new user turn, update this state and trigger a new search/filter operation on the Biznesinfo data based on the cumulative parameters. Ensure the underl…
  impact: Drastically reduce 'generic fallback' issues and ensure responses are highly relevant to the latest user input. Improve continuity across multi-turn conversations.
  risk: Medium (requires careful state management and robust integration with the Biznesinfo search API).
  validate: D001, D005, D006, D008, D011, D003
- [R2] (qa, effort S) Enforce Specific Company Presentation over General Rubrics
  action: Update the main prompt and any post-processing templates to *always* attempt to present specific company names, links, and relevant attributes when search results are available, especially when ranking or shortlisting is requested. Avoid using generic 'how-to-search' instructions or abstract criteria unless *explicitly no companies match the criteria*. For example, if a user asks for 'кого прозвонить первым' after c…
  hint: Modify the prompt to explicitly instruct the model: 'If Biznesinfo data provides specific companies, prioritize listing 2-5 top relevant companies with brief justifications for their ranking/relevance, and include their Biznesinfo links. O…
  impact: Increase actionability and direct usefulness for the user, fulfilling the 'rushed buyer' persona by providing immediately usable information.
  risk: Low (primarily prompt/template adjustment).
  validate: D001, D005, D006, D008, D011, D003
- [R3] (qa, effort S) Transparent Handling of 'No Results' and Data Limitations
  action: When a highly specific query (especially after multiple turns) yields no results from the Biznesinfo catalog, the assistant should clearly and transparently state that no companies were found matching *all* the detailed criteria. It should then offer to broaden the search by removing the *least critical* constraint or suggest alternative search terms, rather than reverting to a generic, unhelpful response or claimin…
  hint: Implement a check after the Biznesinfo data retrieval step. If the result set is empty or below a certain threshold (e.g., <2 companies), trigger a specific 'no results' prompt that guides the model to explain this limitation, suggest broa…
  impact: Build user trust and provide more helpful guidance even in cases of no direct matches. Avoid frustrating users with generic advice when they've provided specific constraints.
  risk: Low.
  validate: D005, D011
- [R4] (qa, effort S) Contextualize General Advice for Identified Companies
  action: For scenarios like D008 ('уборка после ремонта') where contract clauses or checklists are requested, and specific companies have been identified in earlier turns, modify the prompt to instruct the model to *attempt* to contextualize the general advice with references to the previously identified companies (e.g., 'For [Company X], consider clause Y due to Z'). If direct contextualization is not feasible, ensure the g…
  hint: Prepend a summary of previously identified companies (with their key attributes) to the prompt when general advice (like contract terms or checklists) is requested. Explicitly ask the model to integrate this context into its response if po…
  impact: Maintain continuity and increase the perceived relevance and usefulness of general advice by tying it back to specific entities previously discussed.
  risk: Low.
  validate: D008

## kimi

- Summary: Critical pattern detected: assistant suffers from severe continuity failures in multi-turn conversations. After providing concrete company candidates in Turn 1/Turn 2, Turn 3 consistently drops context and falls back to generic rubrics instead of ranking/analyzing the previously identified companies. This affects 5/11 scenarios (D001, D005, D006, D008, D011) with usefulness scores 1-2. Root cause appears to be prompt instructions that prioritize 'avoiding hallucination' over 'continuity with retrieved candidates'.

### Priority Plan

- P0 — Fix continuity context retention for ranking follow-ups
  why: 5 scenarios fail with 'generic fallback' pattern where assistant forgets previously identified companies when asked to rank/analyze them. This is the #1 user-facing defect.
  impact: Increases usefulness score from 1-2 to 4-5 for D006, D008, D005; reduces genericFallbackRate from 54% to <20%
  validate: D006, D008, D005, D001, D011
- P0 — Enforce company path output in ranking/rubric responses
  why: Strict check D001.T3.C3 fails because assistant provides generic questions instead of company-specific shortlist. Users expect /company/ links or explicit references to previously found candidates.
  impact: Fixes 1 strict failure, improves user trust in actionable output
  validate: D001, D003, D004, D005, D006, D008
- P1 — Add geo-filters for micro-districts (Малиновка, Казимировка)
  why: D001 Turn 2 fails to filter 4 identified print shops by Малиновка proximity. Assistant gives generic search instructions instead of analyzing locations.
  impact: Improves usefulness for location-constrained queries; reduces 'generic fallback' rate
  validate: D001, S005, S006
- P1 — Improve constraint incorporation in follow-up turns
  why: D011 fails because assistant ignores '1.5% fat, delivery to Vitebsk' constraints and repeats same processors instead of finding raw milk suppliers.
  impact: Better handling of refined queries; improves continuity score from 1 to 4+
  validate: D011
- P2 — Add specific certification bodies to knowledge base
  why: D007 provides generic certification guide without naming specific Minsk certification organizations from catalog.
  impact: Increases usefulness from 3 to 4-5 for verification/service queries
  validate: D007

### Recommendations

- [R1] (prompt, effort S) Inject candidate memory into Turn 3+ ranking prompts
  action: Modify prompt template to include explicit instruction: 'If user asks for ranking/shortlist/risks and you have previously identified specific companies in this conversation, you MUST reference those exact companies by name and /company/ path. Do NOT provide generic rubrics.'
  hint: File: src/lib/ai/prompts/ranking.ts or similar; add 'previouslyIdentifiedCompanies' context variable that accumulates across turns
  impact: Eliminates generic fallback in D006, D008, D005; improves continuityScore from avg 2.36 to 4+
  risk: Low - only affects multi-turn with existing candidates
  validate: D006, D008, D005, D001
- [R2] (prompt, effort S) Add explicit company path requirement to structured output schema
  action: Update system prompt: 'When providing shortlists, rankings, or comparisons, always include at least one /company/ path OR explicitly state if previously mentioned companies don't match new constraints.'
  hint: Add to response format instructions in base prompt; validate with regex check for /company/ in ranking responses
  impact: Fixes D001.T3.C3 strict failure; ensures actionable output
  risk: Low
  validate: D001, D003, D004, D005
- [R3] (retrieval, effort S) Enable partial UNP search for verification queries
  action: Implement search by partial UNP pattern '19...' when full UNP not provided. Return candidates with matching prefix for user selection.
  hint: src/lib/meilisearch/search.ts - add prefix search filter on unp field; limit to 5 results
  impact: Improves D002 Turn 2 usefulness; enables proactive assistance instead of just asking for full UNP
  risk: Low - only affects verification queries with partial data
  validate: D002
- [R4] (geo, effort M) Add micro-district location filtering in responses
  action: When user specifies district (Малиновка, Казимировка), assistant should check company addresses for proximity keywords before responding. If no match, explicitly state 'none of the previously found companies are in X district'.
  hint: Add location extractor in src/lib/utils/location.ts; check against company.address field in context
  impact: Fixes D001 Turn 2; improves geo-signal handling across all scenarios
  risk: Low
  validate: D001, S005, S006
- [R5] (guardrails, effort S) Remove over-aggressive 'avoid hallucination' fallback triggers
  action: Current prompt likely has strong anti-hallucination instruction causing generic rubrics. Replace with: 'If you have identified companies earlier in this conversation, prioritize referencing them even if your confidence is moderate. Only fall back to generic advice if NO companies were found in previous turns.'
  hint: Review base system prompt for anti-hallucination clauses; soften for continuity preservation
  impact: Reduces genericFallbackRate from 54% to <20%; fixes D006, D008, D011
  risk: Medium - monitor for hallucination increase
  validate: D006, D008, D011, D005
- [R6] (template, effort M) Add contract clause templates for service queries
  action: When user asks 'what to include in contract' (D008), provide specific clauses for cleaning services instead of generic priority rubric.
  hint: Add service-specific contract templates to knowledge base or prompt; trigger when query matches 'договор' + service type
  impact: Improves D008 usefulness from 1 to 4+
  risk: Low
  validate: D008
- [R7] (ranking, effort M) Implement explicit candidate tracking across turns
  action: Add conversation state tracking for 'identifiedCandidates' array. When user asks for ranking/shortlist, system prompt should inject: 'Previously identified: [Company A /company/a], [Company B /company/b]'.
  hint: Modify conversation history processing to extract and inject company mentions into context window
  impact: Prevents continuity failures; ensures consistent candidate references
  risk: Low
  validate: D006, D008, D005, D001, D011
- [R8] (qa, effort S) Add automated continuity check to QA suite
  action: New check: verify that company names from Turn 1/2 appear in Turn 3 response when user asks for ranking/comparison/shortlist.
  hint: Extend scripts/ai-request-qa-runner.mjs with 'continuity_candidates' check type
  impact: Catches regressions in multi-turn candidate retention
  risk: None
  validate: D006, D008, D005, D011

