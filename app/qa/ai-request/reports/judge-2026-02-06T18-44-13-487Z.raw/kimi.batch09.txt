I see the user is asking me to act as an external QA judge to evaluate AI assistant replies in realistic multi-turn business sourcing conversations. Let me analyze the 5 scenarios (S041-S045) and rate them according to the rubric.

Looking at the scenarios, I need to evaluate:

1. **S041** - Shortlist: металлоконструкции (metal structures)
2. **S042** - Shortlist: маркетинг/медиа (marketing/media)
3. **S043** - Shortlist: стройподряд (construction contracting)
4. **S044** - Shortlist: агро/лес (agriculture/forestry)
5. **S045** - Shortlist: mixed B2B

Let me analyze each scenario based on the rubric dimensions:
- Relevance to user intent
- Geo adherence and context continuity
- Actionability and concrete next steps
- Non-hallucination and honesty about limits
- Formatting quality for requested mode

```json
{
  "judge": "kimi",
  "ratings": [
    {
      "scenarioId": "S041",
      "usefulness": 4,
      "verdict": "useful",
      "confidence": 0.85,
      "reasons": [
        "Good relevance: ranks companies by metal structures fit with clear reasoning",
        "Maintains geo context (Minsk) consistently across all turns"
      ],
      "criticalIssues": [],
      "strengths": [
        "Honest about uncertainty (requires verification, conditional ranking)",
        "Clear top-2 ranking with risk assessment in turn 2",
        "Email/WhatsApp templates in turn 3 follow requested format with placeholders"
      ]
    },
    {
      "scenarioId": "S042",
      "usefulness": 3,
      "verdict": "useful",
      "confidence": 0.75,
      "reasons": [
        "Relevant ranking based on service type match",
        "Maintains Minsk context consistently"
      ],
      "criticalIssues": [
        "Turn 3 template has corrupted placeholder text 'шаблон первого' instead of actual service description",
        "Template appears to have echo/repetition bug from user prompt injection"
      ],
      "strengths": [
        "Clear top-2 with transparent logic",
        "Asks clarifying questions to narrow intent"
      ]
    },
    {
      "scenarioId": "S043",
      "usefulness": 4,
      "verdict": "useful",
      "confidence": 0.88,
      "reasons": [
        "Excellent relevance: correctly identifies specialized vs general contractors",
        "Geo context maintained (Minsk/Soligorsk/Svetlogorsk)"
      ],
      "criticalIssues": [],
      "strengths": [
        "Honest about limited info (suggests verifying on company pages)",
        "Detailed risk assessment and clarifying questions for top-2",
        "Professional meeting request template with clear agenda items"
      ]
    },
    {
      "scenarioId": "S044",
      "usefulness": 3,
      "verdict": "useful",
      "confidence": 0.70,
      "reasons": [
        "Relevant comparison for agro/forestry sourcing",
        "Reliability criteria are practical and actionable"
      ],
      "criticalIssues": [
        "Turn 3 template has corrupted placeholder 'шаблон письма' repeated multiple times",
        "Template quality degraded due to prompt echo issue"
      ],
      "strengths": [
        "Good top-2 selection with clear reliability criteria",
        "Comprehensive evaluation framework for long-term partnerships"
      ]
    },
    {
      "scenarioId": "S045",
      "usefulness": 3,
      "verdict": "useful",
      "confidence": 0.72,
      "reasons": [
        "Logical prioritization of material suppliers over services",
        "Transparent ranking logic explained"
      ],
      "criticalIssues": [
        "Turn 3 template has corrupted placeholder 'подготовь стартовый' instead of actual product/service",
        "Template suffers from prompt echo bug"
      ],
      "strengths": [
        "Asks clarifying questions to improve relevance",
        "Good contact completeness check"
      ]
    }
  ]
}
```
